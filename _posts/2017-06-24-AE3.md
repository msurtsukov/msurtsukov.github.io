---
layout: single
title:  "AutoEncoders in Keras: VAE"
excerpt_separator: <!--more-->
---

In the last part, we have already discussed what hidden variables are, looked at their distribution, and also understood that it is difficult to generate new objects from the distribution of latent variables in ordinary autoencoders. In order to be able to generate new objects, the space of latent variables must be predictable.

Variational Autoencoders are autoencoders that learn to map objects into a given hidden space and sample from it. Therefore, variational autoencoders are also referred to the family of generative models.

![pde](/assets/ae/vae.png){: width="400px" .align-center}
Illustration from [here](http://ijdykeman.github.io/ml/2016/12/21/cvae.html)

<!--more-->

Full Russian text is available [here](https://habr.com/ru/post/331552/)

[Repository with jupyter notebook](https://github.com/msurtsukov/ae_vae_gan)
